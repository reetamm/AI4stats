{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOasHo/lqRkZ3PaaxCfRlN6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","We will be using Google Colab for this example on density regression using semi-parametric quantile regression (SPQR). First, go to https://colab.research.google.com/. Click File -> New notebook in Drive, and then change the runtime to R (Runtime -> Change runtime type, then pick R in the dropdown). We will not be using GPUs, so keep the CPU box checked.\n","\n","# Installation\n","To install Keras3, run the following code. Colab already has Python and Tensorflow modules installed, so we do not need to do anything particularly complicated here."],"metadata":{"id":"3U_VMApTEWc_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fCMpUosEPdG"},"outputs":[],"source":["remotes::install_github(\"rstudio/tensorflow\")\n","install.packages(c(\"keras3\",\"splines2\"))\n","library(keras3)"]},{"cell_type":"markdown","source":["Set seed for reproducibility."],"metadata":{"id":"9L_EwS76Ek6a"}},{"cell_type":"code","source":["tensorflow::set_random_seed(1)"],"metadata":{"id":"BJ5QrHEJEmeA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Key functions for SPQR\n","\n","The most important function in the second one, which evaluates the SPQR negative log-likelihood loss function. Since the SPQR likelihood includes M- and I-splines, the first function evaluates those. The final function is a predict function which is a wrapper around the predict function of keras. This function is used to predict PDFs, CDFs, and QFs associated with SPQR fits."],"metadata":{"id":"gbzzLLB6EnSp"}},{"cell_type":"code","source":["# Evaluate basis functions\n","basis <- function(y,K,knots, integral=FALSE){\n","  B     <- splines2::mSpline(y, knots = knots,\n","                   Boundary.knots=c(0,1),\n","                   intercept=TRUE, degree = 2,\n","                   integral=integral)\n","  return(t(B))\n","}\n","\n","# Negative log-likelihood for SPQR\n","nloglik_loss_SPQR  = function (y_true, y_pred){\n","  numbasis <- op_shape(y_true)[[2]]\n","  # print(numbasis)\n","  probs <- y_pred[,1:numbasis]\n","  sumprod <- op_sum(y_true*probs,axis=2)\n","  spqr_loss <- -op_sum(op_log(sumprod))\n","  return(spqr_loss)\n","}\n","\n","# Predict function used on fitted SPQR models\n","predict.SPQR <- function(model,X,Y=NULL,nY=101,tau=0.5,type='QF'){\n","  pred        <- as.matrix(model(X))\n","  n <- nrow(pred)\n","  ntau = length(tau)\n","  n.knots <- ncol(pred)\n","  if(is.null(Y) | type=='QF')\n","    Y <- seq(0,1,length.out = nY)\n","  B <- (basis(Y , n.knots,knots, integral = (type!='PDF')))\n","  if(ncol(B)!=n)\n","    df1  <- pred%*%B\n","  if(ncol(B)==n)\n","    df1  <- colSums(B*t(pred))\n","  if(type!='QF'){\n","    return(df1)\n","  }\n","  if(type=='QF'){\n","    qf1 = matrix(NA,n,ntau)\n","    for(i in 1:n)\n","      qf1[i,] <- stats::approx(df1[i,], Y, xout=tau, ties = list(\"ordered\", min))$y\n","    return(qf1)\n","  }\n","}"],"metadata":{"id":"xODABhwdEvh6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**SPQR parameters**: Other than the neural network hyperparameters, the number of basis function knots is the only thing that needs to be set. Values between 10-25 work well in practice."],"metadata":{"id":"xu-gtZV7Ex9Z"}},{"cell_type":"code","source":["n.knots <- 15\n","knots = seq(1/(n.knots-2), 1-1/(n.knots-2), length=n.knots-3)"],"metadata":{"id":"oH1PB906E2uq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data import and pre-processing\n","\n","This is wildfire data used by [Lawler and Shaby (2024)](https://onlinelibrary.wiley.com/doi/full/10.1002/env.2873) and more recently in [Majumder and Richards (2025)](https://arxiv.org/abs/2504.19994). In particular, we use the `tmax` (maximum temperature) and `pr` (precipitation) data for a specific L3 ecoregion in the US."],"metadata":{"id":"J0Cn6EJ3E5IZ"}},{"cell_type":"code","source":["weather <- readRDS(\"weather2.RDS\")\n","head(weather)"],"metadata":{"id":"dU-13hSoFX2F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instead of modeling the raw precip, we use a log-transform. The data is split in an 80/20 ratio as training and testing."],"metadata":{"id":"vkNRpArXFdDt"}},{"cell_type":"code","source":["mnth <- weather$month\n","tmax <- weather$tmax - 273 #convert tmax to celsius\n","pr <- log(weather$pr + 0.0001) #convert pr to log-scale\n","plot(tmax,pr,pch=20)\n","\n","n_total <- length(tmax)\n","train_ind <- sample(1:n_total,ceiling(0.8*n_total)) #80% training data\n","\n","tmax_range <- range(tmax)\n","y1 <- (tmax - tmax_range[1])/diff(tmax_range) # Rescale tmax to [0,1]\n","X <- cbind(1,pr)\n","\n","# train and validation data\n","y1_train <- y1[train_ind]\n","y1_test <- y1[-train_ind]\n","\n","# For unconditional density, with only intercept\n","X1_train <- matrix(X[train_ind,1],ncol = 1)\n","X1_test <- matrix(X[-train_ind,1],ncol = 1)\n","\n","# For conditional density of tmax with intercept and log-pr\n","X2_train <- X[train_ind,1:2]\n","X2_test <- X[-train_ind,1:2]\n","\n","# Basis functions, whic are the 'output' from the neural networks\n","M_basis_train <- t(basis(y1_train,n.knots,knots))\n","I_basis_train <- t(basis(y1_train,n.knots,knots, integral = TRUE))\n","\n","M_basis_test <- t(basis(y1_test,n.knots,knots))\n","I_basis_test <- t(basis(y1_test,n.knots,knots, integral = TRUE))"],"metadata":{"id":"dMdk2LOAFhJa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling the marginal distribution of `tmax`\n","\n","Building the model: This follows very similar to the previous examples. We consider a very simple model with one input dimension (the intercept), and output dimensions corresponding to the number of knots. In between there is a single hidden layer with 32 neurons and a `relu` activation function. The output layer has a `softmax` activation function which ensures that the output is 15 probabilities that sum to 1.\n","\n","Recall the likelihood for SPQR:\n","$$f(y\\vert x) = \\sum_{k=1}^K \\pi_k(x)M_k(y)$$\n","\n","In the absence of covariates, it would be:\n","$$f(y) = \\sum_{k=1}^K \\pi_kM_k(y)$$\n","\n","As mentioned before, loss functions in `keras` always has two arguments, `y_true` and `y_pred`. In case of SPQR, `y_true` will be the M-basis functions $M_k(y)$ and `y_pred` would be the neural network output probabilities $\\pi_k$."],"metadata":{"id":"yE3xCYEpF1dk"}},{"cell_type":"code","source":["model <- keras_model_sequential()\n","\n","model %>%\n","  # Adds a densely-connected layer with 64 units to the model:\n","  layer_dense(units = 32, input_shape = c(1), activation = 'relu') %>%\n","\n","  # Add a final layer with 1 ouput\n","  layer_dense(units = n.knots, activation = 'softmax')"],"metadata":{"id":"fJaSk_UIGsEm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compile and print the model architecture"],"metadata":{"id":"8NNecVKOHg4f"}},{"cell_type":"code","source":["model %>% compile(\n","  optimizer = \"adam\",\n","  loss = nloglik_loss_SPQR\n","  )\n","model"],"metadata":{"id":"9-L2Z8wsHjbg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the response is not `y` but the M-spline basis functions. We follow up by fitting an SPQR model for the marginal distribution of `tmax`. I'm employing early stopping to prevent overfitting, but not checkpointing in this example."],"metadata":{"id":"-mrRXf9GHmkO"}},{"cell_type":"code","source":["early.stopping <-   callback_early_stopping(monitor = \"val_loss\", patience = 5)\n","\n","history <- model %>% fit(\n","  x = X1_train,\n","  y = M_basis_train,\n","  callbacks = list(early.stopping),\n","  epochs = 100,\n","  batch_size = 128,\n","  verbose = 0,\n","  validation_split = 0.2,\n","  shuffle = T\n",")"],"metadata":{"id":"TtdLfzQXH4B2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Diagnostics**: We first do a QQ-plot on the validation data, which shows a good fit."],"metadata":{"id":"XMhiQKA_IFUI"}},{"cell_type":"code","source":["ycdf = predict.SPQR(model,X=X1_test,Y=y1_test,type = 'CDF')\n","qqplot(runif(length(ycdf)),ycdf)\n","abline(0,1)"],"metadata":{"id":"lwJHv_voII1i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Predictions**: Since there is only the intercept, we just predict f(y)"],"metadata":{"id":"rZg9wIViINkq"}},{"cell_type":"code","source":["ypred = predict.SPQR(model,X=X1_train,type = 'PDF')\n","plot(density(y1_train))\n","lines(seq(0,1,length.out=101),\n","      ypred[1,],lty=2,col='blue','l')"],"metadata":{"id":"obFL2TY_IQrE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling the conditional distribution of `tmax|pr`\n","\n","**Building the model**: The input to the neural network is now both an intercept term and the precipitation. The methodology is otherwise identical."],"metadata":{"id":"Fw_6ZPiOIUat"}},{"cell_type":"code","source":["model1 <- keras_model_sequential()\n","\n","model1 %>%\n","  # Adds a densely-connected layer with 64 units to the model:\n","  layer_dense(units = 32, input_shape = c(2), activation = 'relu') %>%\n","\n","  # Add a final layer with 1 ouput\n","  layer_dense(units = 15, activation = 'softmax')\n","\n","  model1 %>% compile(\n","  optimizer = \"adam\",\n","  loss = nloglik_loss_SPQR\n","  )\n","model1"],"metadata":{"id":"0iLkClrZIhXJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fit the model:"],"metadata":{"id":"ScDmFvirInF1"}},{"cell_type":"code","source":["early.stopping <-   callback_early_stopping(monitor = \"val_loss\", patience = 5)\n","\n","history <- model1 %>% fit(\n","  x = X2_train,\n","  y = M_basis_train,\n","  callbacks = list(early.stopping),\n","  epochs = 100,\n","  batch_size = 128,\n","  verbose = 0,\n","  validation_split = 0.2,\n","  shuffle = T\n",")"],"metadata":{"id":"yBKBVvHwIo-c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Diagnostics**: We do a goodness of fit as before."],"metadata":{"id":"d0yJjnVfIs5F"}},{"cell_type":"code","source":["ycdf = predict.SPQR(model1,X=X2_test,Y=y1_test,type = 'CDF')\n","qqplot(runif(length(ycdf)),ycdf)\n","abline(0,1)"],"metadata":{"id":"n-DTV3_rIwaI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Conditional distributions of `tmax|pr`\n","\n","We plot the conditional distribution of `tmax` for three different precip regimes - no rainfall, 1mm of rainfall, and 6mm of rainfall."],"metadata":{"id":"-RwNEh0DI08H"}},{"cell_type":"code","source":["X_pred <- matrix(c(1,log(0.0001),1,log(1),1,log(6)),ncol=2,byrow = T)\n","ypred = predict.SPQR(model1,X=X_pred,type = 'PDF')\n","\n","#pr=0mm\n","plot(c(0:100)/100,ypred[1,],'l',col='black',xlab = 'y',ylab = 'f(y|x)',ylim=c(0,4))\n","\n","#pr=1mm\n","lines(c(0:100)/100,ypred[2,],'l',col='red')\n","\n","#pr=6mm\n","lines(c(0:100)/100,ypred[3,],'l',col='blue')"],"metadata":{"id":"KjB7VaKXI7vt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Marginal distribution of `tmax`\n","To evaluate the marginal density, we sample a range of pr values, and use marginalization to get the unconditional distribution."],"metadata":{"id":"siHgjknkI9O-"}},{"cell_type":"code","source":["pr_range <- range(pr)\n","# -9.210340  3.440484\n","\n","pr_seq <- seq(pr_range[1],pr_range[2],length.out = 1000)\n","X_pred <- cbind(rep(1,1000),pr_seq)\n","ypred <- predict.SPQR(model1,X=X_pred,type = 'PDF')\n","ypred <- apply(ypred,2,mean)\n","plot(density(y1_train),ylim=c(0,4))\n","lines(seq(0,1,length.out=101),\n","      ypred,lty=2,col='blue','l')"],"metadata":{"id":"TR5OnR50KISZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Probability and quantile estimates\n","\n","The closed form of the CDF means that we can evaluate probability statements associated with the conditional (and marginal) distributions. We can also estimate quantiles.\n","\n"],"metadata":{"id":"uMhNwl_PKLTB"}},{"cell_type":"code","source":["X_pred <- matrix(c(1,log(0.0001),1,log(1),1,log(6)),ncol=2,byrow = T)\n","\n","# Median temperature when there is no rainfall\n","X0 <- matrix(X_pred[1,],nrow = 1)\n","y0 <- predict.SPQR(model1,X=X0,type = 'QF',tau=0.5)\n","y0*diff(tmax_range) + tmax_range[1]\n","\n","# Probability that tmax will be greater than 35 degress when there is no rainfall\n","yyy <- (35-tmax_range[1])/diff(tmax_range)\n","ycdf <- predict.SPQR(model1,X=X0,Y=yyy,type = 'CDF')\n","1 - ycdf"],"metadata":{"id":"nag3P_m_KQOv"},"execution_count":null,"outputs":[]}]}